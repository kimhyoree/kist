{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\L3352\\.conda\\envs\\new2\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\L3352\\.conda\\envs\\new2\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "c:\\Users\\L3352\\.conda\\envs\\new2\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 지정된 경로를 찾을 수 없습니다: '/content/oxford-iiit-pet\\\\images'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 51\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[39mreturn\u001b[39;00m image, mask\n\u001b[0;32m     50\u001b[0m \u001b[39m# 데이터셋과 변환 정의\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m dataset \u001b[39m=\u001b[39m OxfordPetDataset(root_dir\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m/content/oxford-iiit-pet\u001b[39;49m\u001b[39m\"\u001b[39;49m, transform\u001b[39m=\u001b[39;49mToTensor())\n\u001b[0;32m     53\u001b[0m \u001b[39m# 첫 번째 이미지와 마스크 로드\u001b[39;00m\n\u001b[0;32m     54\u001b[0m image, mask \u001b[39m=\u001b[39m dataset[\u001b[39m0\u001b[39m]\n",
      "Cell \u001b[1;32mIn[1], line 28\u001b[0m, in \u001b[0;36mOxfordPetDataset.__init__\u001b[1;34m(self, root_dir, transform)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimages_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(root_dir, \u001b[39m\"\u001b[39m\u001b[39mimages\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmasks_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(root_dir, \u001b[39m\"\u001b[39m\u001b[39mannotations\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtrimaps\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_filenames \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mlistdir(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimages_dir)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 지정된 경로를 찾을 수 없습니다: '/content/oxford-iiit-pet\\\\images'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import ToTensor, Compose\n",
    "from torchvision.datasets import OxfordIIITPet\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms.functional import to_tensor, to_pil_image\n",
    "\n",
    "import os\n",
    "import tarfile\n",
    "from torchvision.datasets import OxfordIIITPet\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class OxfordPetDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images_dir = os.path.join(root_dir, \"images\")\n",
    "        self.masks_dir = os.path.join(root_dir, \"annotations\", \"trimaps\")\n",
    "        self.image_filenames = os.listdir(self.images_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filename = self.image_filenames[idx]\n",
    "        image_path = os.path.join(self.images_dir, image_filename)\n",
    "\n",
    "        # 마스크 파일 이름은 이미지 파일 이름에서 확장자만 바꾸면 됩니다\n",
    "        mask_filename = os.path.splitext(image_filename)[0] + \".png\"\n",
    "        mask_path = os.path.join(self.masks_dir, mask_filename)\n",
    "\n",
    "        image = Image.open(image_path)\n",
    "        mask = Image.open(mask_path)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "# 데이터셋과 변환 정의\n",
    "dataset = OxfordPetDataset(root_dir=\"/content/oxford-iiit-pet\", transform=ToTensor())\n",
    "\n",
    "# 첫 번째 이미지와 마스크 로드\n",
    "image, mask = dataset[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 이미지와 마스크를 시각화합니다\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image.permute(1, 2, 0))  # 이미지의 채널 순서를 변경합니다\n",
    "plt.title('Image')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(mask.squeeze(0), cmap='gray')  # 첫 번째 차원을 제거합니다\n",
    "plt.title('Mask')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        def conv_block(in_channels, out_channels):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "\n",
    "        def pool_block():\n",
    "            return nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        def upsample_block(in_channels, out_channels):\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            conv_block(in_channels, 64),\n",
    "            pool_block(),\n",
    "            conv_block(64, 128),\n",
    "            pool_block(),\n",
    "            conv_block(128, 256),\n",
    "            pool_block(),\n",
    "            conv_block(256, 512),\n",
    "            pool_block()\n",
    "        )\n",
    "\n",
    "        self.middle = conv_block(512, 1024)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            upsample_block(1024, 512),\n",
    "            conv_block(512 + 512, 512),\n",
    "            upsample_block(512, 256),\n",
    "            conv_block(256 + 256, 256),\n",
    "            upsample_block(256, 128),\n",
    "            conv_block(128 + 128, 128),\n",
    "            upsample_block(128, 64),\n",
    "            conv_block(64 + 64, 64)\n",
    "        )\n",
    "\n",
    "        self.output_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder[:2](x)\n",
    "        enc2 = self.encoder[2:5](enc1)\n",
    "        enc3 = self.encoder[5:8](enc2)\n",
    "        enc4 = self.encoder[8:](enc3)\n",
    "\n",
    "        middle = self.middle(enc4)\n",
    "\n",
    "        dec1 = self.decoder[:2](middle)\n",
    "        dec1 = torch.cat([dec1, enc4], dim=1)\n",
    "        dec2 = self.decoder[2:4](dec1)\n",
    "        dec2 = torch.cat([dec2, enc3], dim=1)\n",
    "        dec3 = self.decoder[4:6](dec2)\n",
    "        dec3 = torch.cat([dec3, enc2], dim=1)\n",
    "        dec4 = self.decoder[6:8](dec3)\n",
    "        dec4 = torch.cat([dec4, enc1], dim=1)\n",
    "\n",
    "        out = self.output_conv(dec4)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋의 샘플 수 확인\n",
    "print(\"Dataset length:\", len(dataset))\n",
    "\n",
    "# 이미지와 마스크의 크기 확인\n",
    "print(\"Image size:\", image.size())\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# 정수형 리스트를 NumPy 배열로 변환\n",
    "mask_array = np.array(mask)\n",
    "\n",
    "# NumPy 배열을 PIL 이미지로 변환\n",
    "mask_image = Image.fromarray(mask_array)\n",
    "\n",
    "# PIL 이미지를 텐서로 변환\n",
    "mask_tensor = to_tensor(mask_image)\n",
    "\n",
    "print(\"Mask size:\", mask_tensor.size())\n",
    "\n",
    "\n",
    "\n",
    "# UNet 모델 구조 확인\n",
    "model = UNet(in_channels=3, out_channels=1)  # 입력 채널 수와 출력 채널 수에 맞게 수정\n",
    "print(model)\n",
    "\n",
    "# 입력 이미지를 모델에 전달하여 출력 확인\n",
    "output = model(image.unsqueeze(0))\n",
    "print(\"Output size:\", output.size())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
